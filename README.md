# CSE 842 Homework 2
## Question 1

```
python liujia45_hmm.py
```

We can get a sample of the 2 matrices as below:
```
 A: [[6.09901581e-02 7.29197733e-02 5.51744706e-03 2.59469132e-02
  5.36832687e-03 7.09961229e-01 1.89382642e-02 1.61049806e-02
  2.53504324e-03 1.59558604e-02 6.54637638e-02 2.98240382e-04]
 [7.71347633e-02 1.69162282e-02 1.07648725e-02 1.05220558e-03
  4.40226629e-01 3.06029947e-01 5.85997572e-02 8.57952246e-03
  3.39943343e-02 3.77984622e-02 8.57952246e-03 3.23755565e-04]
 [1.20334428e-01 1.56166020e-01 7.55449388e-02 1.58256196e-02
  8.12182741e-02 5.55389669e-02 2.41863243e-02 2.83666766e-02
  3.64287847e-02 2.73514482e-01 1.32875485e-01 0.00000000e+00]
 [1.07839529e-01 5.74162679e-02 5.81523739e-02 0.00000000e+00
  1.43540670e-01 3.45233714e-01 2.76039750e-02 2.42914980e-02
  4.23260950e-02 1.76297387e-01 1.69304380e-02 3.68053000e-04]
 [2.33558697e-01 8.07796997e-03 1.31706032e-02 3.51216086e-04
  5.26824129e-03 6.47379050e-01 1.89656686e-02 1.75608043e-03
  5.70726139e-03 5.42628852e-02 1.05364826e-02 9.65844236e-04]
 [1.70287728e-02 2.12663926e-01 2.06498336e-02 4.75305017e-02
  1.36034449e-02 2.59639851e-01 1.05369609e-02 1.68330397e-02
  1.22006916e-02 1.36752137e-01 2.52234619e-01 3.26221700e-04]
 [6.97137581e-02 1.32502308e-01 3.69344414e-02 2.90858726e-02
  1.06186519e-02 4.12742382e-01 1.52354571e-02 6.92520776e-03
  4.15512465e-03 4.61680517e-02 2.35918744e-01 0.00000000e+00]
 [1.76678445e-02 1.02031802e-01 3.31272085e-02 8.39222615e-03
  8.03886926e-02 4.15194346e-02 1.19257951e-02 9.71731449e-03
  2.20848057e-03 6.51501767e-01 4.15194346e-02 0.00000000e+00]
 [9.07297830e-03 4.57593688e-02 5.83826430e-02 1.18343195e-02
  1.22287968e-02 7.49506903e-03 1.18343195e-03 2.16962525e-02
  6.70611440e-03 7.61341223e-01 6.42998028e-02 0.00000000e+00]
 [5.12535593e-02 1.73970415e-01 7.32689770e-02 9.65344816e-03
  1.79943052e-01 1.27925550e-01 1.76401139e-02 6.70879922e-02
  3.20161122e-02 2.02444614e-01 6.47267171e-02 6.94492673e-05]
 [4.30954976e-02 1.02540454e-01 5.24859562e-02 6.40563428e-02
  1.63243062e-01 2.34426092e-01 2.54045443e-02 2.46499539e-02
  7.79743439e-02 1.00444370e-01 1.10673262e-01 1.00612057e-03]
 [0.00000000e+00 5.43478261e-02 1.08695652e-02 1.08695652e-02
  0.00000000e+00 1.19565217e-01 0.00000000e+00 1.08695652e-02
  0.00000000e+00 2.17391304e-02 2.17391304e-01 5.54347826e-01]]
```

```
B: [[0.         0.         0.5        0.25       0.         0.25
  0.        ]
 [0.         0.         0.         0.79411765 0.20588235 0.
  0.        ]
 [0.         0.22641509 0.77358491 0.         0.         0.
  0.        ]
 [0.         0.         0.         0.         1.         0.
  0.        ]
 [0.         0.         0.         0.         0.         0.
  0.        ]
 [0.5        0.         0.         0.         0.         0.
  0.5       ]
 [0.         0.         0.         0.         0.         0.
  0.        ]
 [0.         1.         0.         0.         0.         0.
  0.        ]
 [0.         0.         0.         0.         0.         0.
  0.        ]
 [0.         0.         0.         1.         0.         0.
  0.        ]
 [0.         0.         0.         0.         0.         0.
  0.        ]
 [0.         0.         0.         0.         0.         0.
  0.        ]]
```

For B, we only consider 7 words including ['science','all','well','like','but','red','dog'].

## Question 2

1. Run `python liujia45_nn.py` to get the results for one demo setting "embedding_dim=128, hidden_size=64, batch_size=32, epochs=1" and including all the features ("is_capitalized", "word_length", "contains_digit", "contains_hyphen", "is_title").
2. My model architecture is a keras simpleRNN with an embedding layer in the beginning and a dense layer in the end. 
3. For more experiment results, I include all the results as below:

Fixing embedding_dim = 128, hidden_size = 64, batch_size = 32, and epochs = 1:

|                               | Test Acc |
|-------------------------------|----------|
| no features                   | 93.74%   |
| 1 feature (+is_capitalize)    | 93.08%   |
| 2 features (+contains_digit)  | 93.84%   |
| 3 features (+contains_hyphen) | 93.45%   |
| 4 features (+is_title)        | 93.17%   |
| 5 features (+word_length)     | 95.81%   |

Having all 5 features, hidden_size = 64, batch_size = 32, and epochs = 1:

| embedding_dim                      | Test Acc |
|-------------------------------|----------|
| 32                   | 94.41%   |
| 64    |  95.59%   |
| 128  | 95.81%   |

Having all 5 features, embedding_dim = 128, batch_size = 32, and epochs = 1:

| hidden_size                     | Test Acc |
|-------------------------------|----------|
| 16                  | 95.15% |
| 32                   |  96.14% |
| 64    |  95.81%  |

Having all 5 features, embedding_dim = 128, hidden_size = 32, and epochs = 1:

| batch_size                     | Test Acc |
|-------------------------------|----------|
| 4                  | 99.24% |
| 8                  | 98.47% |
| 16                  | 97.56% |
| 32                   |  96.14% |

Having all 5 features, embedding_dim = 128, hidden_size = 32, batch_size= 4:

| Epoch                    | Val Acc |
|-------------------------------|----------|
| 1                  |  99.30% |
| 2                   | 99.57% |
| 3                   | 99.60%  |
| 4                   |  99.63% |
| 5                   |  99.64% |
| 6                  |  99.62% |
| 7                   | 99.62% |
| 8                   | 99.60%  |
| 9                   | 99.59%  |
| 10                   |  99.58% |
| Final Test Acc        | 99.59%  |
